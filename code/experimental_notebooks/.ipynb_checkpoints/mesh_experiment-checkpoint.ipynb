{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4a9f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f2bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMeSH(fin):\n",
    "    \"\"\"\n",
    "    Given a file-like object, generates MeSH objects, i.e.\n",
    "    dictionaries with a list of values for each qualifier.\n",
    "    Example: {\"MH\": [\"Acetylcysteine\"]}\n",
    "    \"\"\"\n",
    "    currentEntry = None\n",
    "    for line in fin:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        # Handle new record. MeSH explicitly marks this\n",
    "        if line == \"*NEWRECORD\":\n",
    "            # Yiel old entry, initialize new one\n",
    "            if currentEntry:\n",
    "                yield currentEntry\n",
    "            currentEntry = defaultdict(list)\n",
    "            continue\n",
    "        # Line example: \"MH = Acetylcysteine\"\n",
    "        key, _, value = line.partition(\" = \")\n",
    "        # Append to value list\n",
    "        currentEntry[key].append(value)\n",
    "    # If there is a non-empty entry left, yield it\n",
    "    if currentEntry:\n",
    "        yield currentEntry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "030cb1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nodepath_and_label_to_endnode_to_networkx(temp_nx,temp_mesh_entry):\n",
    "    '''\n",
    "    We receive a networkx label and a single mesh entry\n",
    "    we split the MN into multiple labels\n",
    "    we split each label into a list of perpetually growing strings (A01, A01.032, A01.032,047)\n",
    "    we add the \"word label\" at the end from teh MH\n",
    "    '''\n",
    "\n",
    "    #MN and MH are 'attributes' in the ascii text file\n",
    "    #MN is all paths\n",
    "    #MH is the end node\n",
    "    nodepath_string_path_list=temp_mesh_entry['MN']\n",
    "    \n",
    "    #confirm that we are adding the right label always because there is only one\n",
    "    if (len(temp_mesh_entry['MH']))>1:\n",
    "        print(temp_mesh_entry['MH'])\n",
    "        hold=input('found an entry with multiple labels')\n",
    "    end_node_label=temp_mesh_entry['MH'][0]\n",
    "\n",
    "\n",
    "    for temp_string_path in nodepath_string_path_list:\n",
    "        node_path_elements=temp_string_path.split('.')\n",
    "        node_paths=list()\n",
    "\n",
    "        for i in range(0,len(node_path_elements)):\n",
    "            node_paths.append('.'.join(node_path_elements[0:i+1]))\n",
    "\n",
    "        #print(node_paths)\n",
    "        #hold=input('node_paths')\n",
    "\n",
    "        #if 'A11' in node_paths:\n",
    "            nx.add_path(temp_nx,node_paths)\n",
    "        temp_nx.nodes[node_paths[-1]]['mesh_label']=end_node_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc6e367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a95938ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_file_address='../../resources/mesh_ascii_2021.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c8795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_networkx=nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a959a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mesh_file_address, \"r\") as infile:\n",
    "    # readMeSH() yields MeSH objects, i.e. dictionaries\n",
    "    for entry in readMeSH(infile):\n",
    "         add_nodepath_and_label_to_endnode_to_networkx(mesh_networkx,entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cfeb724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of all of the current \"headnodes\". which are Letter+two digits\n",
    "number_string_list=['01','02','03','04','05','06','07','08','09']+[str(i) for i in range(10,51)]\n",
    "possible_headnodes_list=list()\n",
    "for i in ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']:\n",
    "    for j in [str(i) for i in number_string_list]:\n",
    "        possible_headnodes_list.append(i+j)\n",
    "headnodes_list=[element for element in possible_headnodes_list if (element in mesh_networkx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f1f310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b984d095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new set of headnodes\n",
    "category_headnodes={\n",
    "    'A':'Anatomy',\n",
    "    'B':'Organisms',\n",
    "    'C':'Diseases',\n",
    "    'D':'Chemicals and Drugs',\n",
    "    'E':'Analytical, Diagnostic and Therapeutic Techniques, and Equipment',\n",
    "    'F':'Psychiatry and Psychology',\n",
    "    'G':'Phenomena and Processes',\n",
    "    'H':'Disciplines and Occupations',\n",
    "    'I':'Anthropology, Education, Sociology, and Social Phenomena',\n",
    "    'J':'Technology, Industry, and Agriculture',\n",
    "    'K':'Humanities',\n",
    "    'L':'Information Science',\n",
    "    'M':'Named Groups',\n",
    "    'N':'Health Care',\n",
    "    'V':'Publication Characteristics',\n",
    "    'Z':'Geographicals'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14870933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the category headnodes\n",
    "for element in category_headnodes.keys():\n",
    "    mesh_networkx.add_node(element,mesh_label=category_headnodes[element])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bbe7d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'A01'), ('A', 'A02'), ('A', 'A03'), ('A', 'A04'), ('A', 'A05'), ('A', 'A06'), ('A', 'A07'), ('A', 'A08'), ('A', 'A09'), ('A', 'A10'), ('A', 'A11'), ('A', 'A12'), ('A', 'A13'), ('A', 'A14'), ('A', 'A15'), ('A', 'A16'), ('A', 'A17'), ('A', 'A18'), ('A', 'A19'), ('A', 'A20'), ('A', 'A21'), ('B', 'B01'), ('B', 'B02'), ('B', 'B03'), ('B', 'B04'), ('B', 'B05'), ('C', 'C01'), ('C', 'C04'), ('C', 'C05'), ('C', 'C06'), ('C', 'C07'), ('C', 'C08'), ('C', 'C09'), ('C', 'C10'), ('C', 'C11'), ('C', 'C12'), ('C', 'C13'), ('C', 'C14'), ('C', 'C15'), ('C', 'C16'), ('C', 'C17'), ('C', 'C18'), ('C', 'C19'), ('C', 'C20'), ('C', 'C21'), ('C', 'C22'), ('C', 'C23'), ('C', 'C24'), ('C', 'C25'), ('C', 'C26'), ('D', 'D01'), ('D', 'D02'), ('D', 'D03'), ('D', 'D04'), ('D', 'D05'), ('D', 'D06'), ('D', 'D08'), ('D', 'D09'), ('D', 'D10'), ('D', 'D12'), ('D', 'D13'), ('D', 'D20'), ('D', 'D23'), ('D', 'D25'), ('D', 'D26'), ('D', 'D27'), ('E', 'E01'), ('E', 'E02'), ('E', 'E03'), ('E', 'E04'), ('E', 'E05'), ('E', 'E06'), ('E', 'E07'), ('F', 'F01'), ('F', 'F02'), ('F', 'F03'), ('F', 'F04'), ('G', 'G01'), ('G', 'G02'), ('G', 'G03'), ('G', 'G04'), ('G', 'G05'), ('G', 'G06'), ('G', 'G07'), ('G', 'G08'), ('G', 'G09'), ('G', 'G10'), ('G', 'G11'), ('G', 'G12'), ('G', 'G13'), ('G', 'G14'), ('G', 'G15'), ('G', 'G16'), ('G', 'G17'), ('H', 'H01'), ('H', 'H02'), ('I', 'I01'), ('I', 'I02'), ('I', 'I03'), ('J', 'J01'), ('J', 'J02'), ('J', 'J03'), ('K', 'K01'), ('L', 'L01'), ('M', 'M01'), ('N', 'N01'), ('N', 'N02'), ('N', 'N03'), ('N', 'N04'), ('N', 'N05'), ('N', 'N06'), ('V', 'V01'), ('V', 'V02'), ('V', 'V03'), ('V', 'V04'), ('Z', 'Z01')]\n"
     ]
    }
   ],
   "source": [
    "#connect the original headnodes to the category headnodes\n",
    "temp_edges=list()\n",
    "for element in headnodes_list:\n",
    "    temp_edges.append(\n",
    "        (element[0],element)\n",
    "    )\n",
    "print(temp_edges)\n",
    "mesh_networkx.add_edges_from(temp_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f027e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the true headnode\n",
    "mesh_networkx.add_node('root',mesh_label='root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a38c838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect the category headnoes to the true headnode\n",
    "temp_edges=[('root',element) for element in headnodes_list]\n",
    "mesh_networkx.add_edges_from(temp_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3e4d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "organism_nodes=[\n",
    "    element for element in mesh_networkx.nodes if 'B' in element\n",
    "]\n",
    "organism_nodes\n",
    "mesh_networkx.remove_nodes_from(organism_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "948b49f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_that_encapulates_node_id={\n",
    "    'mesh_label'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1258c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(xs):\n",
    "    '''\n",
    "    given a list of elements (can contain arbitrarily nested lists)\n",
    "    creates a generator? of flattned elements\n",
    "    warning: strings will become lists of char\n",
    "    '''\n",
    "    for x in xs:\n",
    "        if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):\n",
    "            yield from flatten(x)\n",
    "        else:\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db39831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_values_to_node_id_dict(temp_nx,temp_node,relevant_node_set):\n",
    "    '''\n",
    "    This takes a single node and returns a dict\n",
    "    where the keys (probably many) are the nested values of the node\n",
    "    and the value for each key is the node ID\n",
    "    '''\n",
    "    one_node_id_dict=dict()\n",
    "    #we make scientific name the endpoint so that it works like the mesh hierarchies\n",
    "    #scientific_name=temp_nx.nodes[temp_node][temp_attribute]\n",
    "    for temp_attribute in relevant_node_set:\n",
    "        #print(temp_attribute)\n",
    "        if temp_attribute not in temp_nx.nodes[temp_node].keys():\n",
    "            continue\n",
    "        elif isinstance(temp_nx.nodes[temp_node][temp_attribute],str):\n",
    "            #print(total_ncbi_networkx.nodes[temp_node][temp_attribute])\n",
    "            one_node_id_dict[temp_nx.nodes[temp_node][temp_attribute]]=temp_node\n",
    "        else:\n",
    "            #print(set(flatten(total_ncbi_networkx.nodes[temp_node][temp_attribute])))\n",
    "            temp_dict={\n",
    "                element:temp_node for element in set(flatten(temp_nx.nodes[temp_node][temp_attribute]))\n",
    "            }\n",
    "            one_node_id_dict.update(temp_dict)\n",
    "    return one_node_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb5c7b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_attribute_to_node_id_dict(temp_nx,relevant_node_set):\n",
    "    '''\n",
    "    takes an entire networkx and features that help to differentiate nodes\n",
    "    returns a dict of {attribute:node_id}\n",
    "    '''\n",
    "    total_feature_node_id_dict=dict()\n",
    "    for i,temp_node in enumerate(temp_nx.nodes):\n",
    "        #get 0.1% of the data\n",
    "        #if i%1000!=0:\n",
    "        #    continue\n",
    "        total_feature_node_id_dict.update(\n",
    "            create_one_values_to_node_id_dict(temp_nx,temp_node,relevant_node_set)\n",
    "        )\n",
    "    return total_feature_node_id_dict\n",
    "#         if i >1000:\n",
    "#             break\n",
    "    #print(total_feature_node_id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13f11894",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_output=create_all_attribute_to_node_id_dict(\n",
    "    mesh_networkx,\n",
    "    set_that_encapulates_node_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef04bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mesh_names.json', 'w') as fp:\n",
    "    json.dump(my_output, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44bf70b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f3bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83d8d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# irrelevant_categories=['B']\n",
    "# for element in irrelevant_categories:\n",
    "#     mesh_networkx.remove_nodes_from(nx.algorithms.dag.descendants(mesh_networkx,element))\n",
    "#     mesh_networkx.remove_nodes_from(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "148664de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_string_list=['01','02','03','04','05','06','07','08','09']+[str(i) for i in range(10,51)]\n",
    "# total_organ_headnodes_list=[]\n",
    "\n",
    "# for i in ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']:\n",
    "#     for j in number_string_list:\n",
    "#         total_organ_headnodes_list.append(i+j)\n",
    "# organ_headnodes_list=[i for i in total_organ_headnodes_list if (i in organ_networkx.nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dea9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe62d832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048be5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e311efd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b356be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
